{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "from random import *\n",
    "import pandas\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import PIL\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4001\n",
      "4001\n",
      "1001\n",
      "1001\n"
     ]
    }
   ],
   "source": [
    "root='/home/zeno/pytorchnotebooks/dataset/'\n",
    "\n",
    "dogstestset=''.join(root+'test_set/'+'dogs/')\n",
    "catstestset=''.join(root+'test_set/'+'cats/')\n",
    "dogstrainset=''.join(root+'training_set/'+'dogs/')\n",
    "catstrainset=''.join(root+'training_set/'+'cats/')\n",
    "\n",
    "print(len(os.listdir(dogstrainset)))\n",
    "print(len(os.listdir(catstrainset)))\n",
    "print(len(os.listdir(dogstestset)))\n",
    "print(len(os.listdir(catstestset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128) (128, 128)\n"
     ]
    }
   ],
   "source": [
    "#use when want to show randomly selected sample image\n",
    "sample_index=randint(1,4001)\n",
    "dog_img=os.listdir(dogstrainset)[sample_index]\n",
    "path2dog_img=dogstrainset+dog_img\n",
    "cat_img=os.listdir(catstrainset)[sample_index]\n",
    "path2cat_img=catstrainset+cat_img\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "imd = Image.open(path2dog_img).convert('L') # use only gray \n",
    "imc=Image.open(path2cat_img).convert('L')\n",
    "\n",
    "resized_d.show()\n",
    "resized_c.show()\n",
    "#resize the image to 128 128\n",
    "resized_d=imd.resize((128,128))\n",
    "resized_c=imc.resize((128,128))\n",
    "\n",
    "resized_d.show()\n",
    "resized_c.show()\n",
    "# convert to np array\n",
    "dog_np=np.asarray(resized_d)\n",
    "cat_np=np.asarray(resized_c)\n",
    "\n",
    "print(dog_np.shape,cat_np.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of imgs:1000, shape(img):(80, 80), label:1.0\n",
      "num of imgs:1000, shape(img):(80, 80), label:0.0\n",
      "num of imgs:4000, shape(img):(80, 80), label:1.0\n",
      "num of imgs:4000, shape(img):(80, 80), label:0.0\n"
     ]
    }
   ],
   "source": [
    "# convert all image to equal size and put into np array and add labels\n",
    "cat_or_dog=[\"cat\",\"dog\"]\n",
    "def image_to_numpy(path,cat_or_dog):\n",
    "    #  cat is 0. and dog is 1.\n",
    "    ls=[]\n",
    "    l=len(os.listdir(path))-1 # last one is .DS_Store \n",
    "    \n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith('.jpg'):\n",
    "            #print('process file:{}'.format(file))\n",
    "            im=Image.open(path+file).convert('L')\n",
    "            im_resized=im.resize((80,80))\n",
    "            im_to_np=np.asarray(im_resized,dtype=np.float32)\n",
    "            ls.append(im_to_np)\n",
    "            im.close()\n",
    "        else:\n",
    "            pass\n",
    "    return [cat_or_dog for i in range(len(ls))], ls\n",
    "    \n",
    "test_label_dog,test_dog=image_to_numpy(dogstestset,1.)\n",
    "test_label_cat,test_cat=image_to_numpy(catstestset,0.)\n",
    "train_label_dog,train_dog=image_to_numpy(dogstrainset,1.)\n",
    "train_label_cat,train_cat=image_to_numpy(catstrainset,0.)\n",
    "print(\"num of imgs:{}, shape(img):{}, label:{}\".format(len(test_dog),test_dog[0].shape,test_label_dog[0]))\n",
    "print(\"num of imgs:{}, shape(img):{}, label:{}\".format(len(test_cat),test_cat[0].shape,test_label_cat[0]))\n",
    "print(\"num of imgs:{}, shape(img):{}, label:{}\".format(len(train_dog),train_dog[0].shape,train_label_dog[0]))\n",
    "print(\"num of imgs:{}, shape(img):{}, label:{}\".format(len(train_cat),train_cat[0].shape,train_label_cat[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 (1, 80, 80) (1, 80, 80)\n",
      "8000 (1,) (1,)\n",
      "2000 (1, 80, 80)\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "#compose train_dat, train_label as well as test_data ,test_label are all numpy arrays now\n",
    "\n",
    "import itertools\n",
    "train_dat=list(itertools.chain(train_dog,train_cat)) \n",
    "train_dat=np.array(train_dat).reshape(8000,1,80,80)\n",
    "\n",
    "train_label=list(itertools.chain(train_label_dog,train_label_cat))\n",
    "train_label=np.array([[item] for item in train_label])\n",
    "\n",
    "test_dat=list(itertools.chain(test_dog,test_cat))\n",
    "test_dat=np.array(test_dat).reshape(2000,1,80,80)\n",
    "\n",
    "test_label=list(itertools.chain(test_label_dog,test_label_cat))\n",
    "test_label=np.array([[item] for item in test_label])\n",
    "\n",
    "\n",
    "print(len(train_dat),train_dat[0].shape,train_dat[4001].shape)\n",
    "print(len(train_label), train_label[0].shape, train_label[4001].shape)\n",
    "print(len(test_dat),test_dat[0].shape)\n",
    "print(len(test_label))\n",
    "#test_dat,test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import  *\n",
    "class SampleMaker(object):\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "    \n",
    "    def push(self, event):\n",
    "        #each event is a tuple of numpy arrays label 1,1 and dat(128,128)\n",
    "        #convert to torch.floatTensor\n",
    "        event2torch=event[0]       \n",
    "        event_label=event[1]       \n",
    "        self.memory.append([event2torch,event_label])  \n",
    "\n",
    "  \n",
    "        if len(self.memory) > self.capacity:\n",
    "            del self.memory[0]\n",
    "    \n",
    "    def make(self, batch_size):\n",
    "        samples = sample(*(self.memory, batch_size))\n",
    "       \n",
    "        return samples\n",
    "        #return map(lambda x: Variable(torch.cat(x, 0)), samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populate the SampleMaker \n",
    "samplemaker=SampleMaker(capacity=8000)\n",
    "for i in range(8000):\n",
    "    #print(test_dat[i].shape, test_label[i].shape)\n",
    "    samplemaker.push([train_dat[i],train_label[i]])    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def type_converter(sam,batch_size):\n",
    "    train_placeholder=np.empty((1,80,80),dtype=float,order='C')\n",
    "    train_labels=np.empty((1,1),dtype=float,order='C')\n",
    "    batch=map(lambda s: s[0],sam)\n",
    "    #convert batch\n",
    "    for o in enumerate(batch):\n",
    "        #print(o[1].shape)\n",
    "        train_placeholder=np.vstack((train_placeholder,o[1]))\n",
    "    train_batches=np.delete(train_placeholder, 0, 0).reshape(batch_size,1,80,80) #delete the empty placeholder\n",
    "    \n",
    "    batch_labels=list(map(lambda s:s[1],sam))\n",
    "    batch_labels=[l.tolist() for l in batch_labels]#convert to list\n",
    "    batch_labels=list(itertools.chain(*batch_labels))#flattern to flatlist\n",
    "    batch_labels=[int(i) for i in batch_labels]#turn each inner-list type to int \n",
    "    batch_labels=np.array(batch_labels)#convert to np array\n",
    "    #returning nd array for train batches and labels\n",
    "    return train_batches,batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Samplemaker's output\n",
    "samples=sample(*(samplemaker.memory,10))\n",
    "t,l=type_converter(samples,10)\n",
    "print(t.shape, type(t))\n",
    "print(type(l), l)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#convert the train batches and labels to torch tensors and put into the learn\n",
    "tr_batches=torch.from_numpy(t).float()\n",
    "tr_labels=torch.from_numpy(l)\n",
    "print(type(tr_batches),tr_batches.size())\n",
    "print(type(tr_labels),tr_labels.size())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'> torch.Size([2000, 1, 80, 80])\n",
      "<class 'torch.DoubleTensor'> torch.Size([2000, 1])\n"
     ]
    }
   ],
   "source": [
    "#covert the test data and labels into torch tensors\n",
    "test_load=torch.from_numpy(test_dat).float()\n",
    "print(type(test_load),test_load.size())\n",
    "test_label=torch.from_numpy(test_label)\n",
    "print(type(test_label),test_label.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for i in range(2000):\n",
    "    print(test_dat[i].size(),test_label[i].size())\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_class):\n",
    "        super(CNN, self).__init__()\n",
    "        # in_channel=1 color , out_channel=hyper param, kernerl_size=hyper param\n",
    "        self.convolution1 = nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 5)\n",
    "        # in_channel=32 previous out_channel , out_channel=hyper param, kernerl_size=hyper param\n",
    "        self.convolution2 = nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3)\n",
    "        # in_channel=32=previous out_channel , out_channel=hyper param, kernerl_size=hyper param\n",
    "        self.convolution3 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 2)\n",
    "        #to obtain numOfNeurons to input to fc1, we use a function count_neurons()\n",
    "        self.fc1 = nn.Linear(in_features = self.count_neurons((1,80,80)), out_features = 40)\n",
    "        self.fc2 = nn.Linear(in_features = 40, out_features = num_class)\n",
    "\n",
    "    def count_neurons(self, image_dim):\n",
    "        #image_dim=(1,80,80) obtained from image_preprocessing.py\n",
    "        x = Variable(torch.rand(1, *image_dim))#create fake image comply to dimensions feed to pytorch Variable\n",
    "        #print('torch Variable x',x.size())   # variable 1x1x80x80\n",
    "        x = F.relu(F.max_pool2d(self.convolution1(x), 3, 2))\n",
    "        #print('first conv-maxpool x',x.size())# 1st conv-maxpool 1x32x37x37 torch.FloatTensor\n",
    "        x = F.relu(F.max_pool2d(self.convolution2(x), 3, 2))\n",
    "        #print('second conv-maxpool x',x.size())#2nd conv-maxpool 1x32x17x17 \n",
    "        x = F.relu(F.max_pool2d(self.convolution3(x), 3, 2))\n",
    "        #print('3rd conv-maxpool x',x.size())#3rd conv-maxpool 1x64x7x7\n",
    "        #pytorch trick to get shape/num of neurons out of Conv  layers\n",
    "        #print('x.data',x.data) #1x64x7x7\n",
    "        #print('x.data.view(1,-1)',x.data.view(1,-1))\n",
    "        #x.data.view(1,-1) is a torch.FloatTensor 1x3136 \n",
    "        # 0.0000  0.0000  0.0000  ...   0.1507  0.1516  0.1373 \n",
    "        return x.data.view(1, -1).size(1) # class :int\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.size())\n",
    "        y = F.relu(F.max_pool2d(self.convolution1(x), 3, 2)) # apply max_pool2d here\n",
    "        y = F.relu(F.max_pool2d(self.convolution2(y), 3, 2)) #apply max_pool2d here\n",
    "        y = F.relu(F.max_pool2d(self.convolution3(y), 3, 2)) #apply max_pool2d here\n",
    "        y = y.view(x.size(0), -1) # similar way to extract total num of neurons to feed fc1\n",
    "        y = F.relu(self.fc1(y))\n",
    "        y = self.fc2(y)\n",
    "        return y\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=CNN(2)\n",
    "#print(model.count_neurons((1,80,80)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dqn():\n",
    "    def __init__(self, num_class):\n",
    "        self.reward_window = []\n",
    "        self.model = CNN(num_class)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr = 0.001)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def make_prediction(self, img):\n",
    "        #img has to be a torch tensor of size 1,80,80\n",
    "        #print(img.unsqueeze(0).size())\n",
    "        test_outputs = self.model.forward(Variable(img.unsqueeze(0)))\n",
    "        #print(\"test_outputs:{}\".format(test_outputs))\n",
    "                \n",
    "        # Get predictions from the maximum value\n",
    "        probs = F.softmax(test_outputs) # T=100\n",
    "        print(\"probs:{}\",probs)\n",
    "        action = probs.multinomial()\n",
    "        print(action)\n",
    "        #print(\"predicted:{}\".format(predicted))\n",
    "        #predicted=predicted.double() # convert Longtensor to DoubleTensor\n",
    "        #pred=predicted.numpy().tolist()[0]\n",
    "        \n",
    "        return action.data[0,0]     \n",
    "\n",
    "        \n",
    "    \n",
    "    def learn(self, batch, targets, test,test_labels,load_model=False):\n",
    "        images = Variable(batch)\n",
    "        labels = Variable(targets)\n",
    "        iter=0\n",
    "        if load_model:\n",
    "            self.load()\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = self.model(images)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        self.optimizer.step()             \n",
    "        \n",
    "        \n",
    "        # Calculate Accuracy         \n",
    "        correct = 0\n",
    "        false_positive=0\n",
    "        false_negative=0\n",
    "        total = len(test_labels)\n",
    "        # Iterate through test dataset\n",
    "        \n",
    "        test_imgs = Variable(test)\n",
    "        #test_labels = Variable(test_labels)\n",
    "        \n",
    "        for i in range(len(test_imgs)):\n",
    "        # Forward pass only to get logits/output\n",
    "            test_outputs = self.model(test_imgs[i].unsqueeze(0))\n",
    "                \n",
    "            # Get predictions from the maximum value\n",
    "            _, predicted = torch.max(test_outputs.data, 1)\n",
    "            predicted=predicted.double() # convert Longtensor to DoubleTensor\n",
    "            #print('i:{}, type of predicted:{},predicted'.format(i,type(predicted),predicted))\n",
    "            # Total number of labels\n",
    "            #print('i: {},type of test_labels[i]:{},test_labels[i];{}'.format(i,type(test_labels[i]),test_labels[i]))\n",
    "            #convert torch tensors back to numpy array and then list and then extract emelemnt inside the list\n",
    "            #print(predicted.numpy().tolist()[0],test_labels[i].numpy().tolist()[0])\n",
    "            pred=predicted.numpy().tolist()[0] # now it is of type float\n",
    "            label=test_labels[i].numpy().tolist()[0]# now it is of type float\n",
    "            \n",
    "                        \n",
    "            if (pred ==label):\n",
    "                correct += 1\n",
    "            elif (pred==1.0 and label==0.):\n",
    "                false_positive+=1\n",
    "            else:\n",
    "                false_negative+=1\n",
    "                #print(\"predicted:{},test_labels[{}]:{}\".format(predicted,i,test_labels[i]))\n",
    "        accuracy = 100 * correct / total\n",
    "        iter+=1\n",
    "        # Print Loss\n",
    "        print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data[0], accuracy))\n",
    "    def save(self):\n",
    "        torch.save({'state_dict': self.model.state_dict(),\n",
    "                    'optimizer' : self.optimizer.state_dict(),\n",
    "                   }, 'last_brain.pth')\n",
    "    def load(self):\n",
    "        if os.path.isfile('last_brain.pth'):\n",
    "            print(\"=> loading checkpoint... \")\n",
    "            checkpoint = torch.load('last_brain.pth')\n",
    "            self.model.load_state_dict(checkpoint['state_dict'])\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"done !\")\n",
    "        else:\n",
    "            print(\"no checkpoint found...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint... \n",
      "done !\n",
      "Iteration: 1. Loss: 0.6450989246368408. Accuracy: 65.85\n",
      "=> loading checkpoint... \n",
      "done !\n",
      "Iteration: 1. Loss: 0.6083582043647766. Accuracy: 65.4\n",
      "=> loading checkpoint... \n",
      "done !\n",
      "Iteration: 1. Loss: 0.6198220252990723. Accuracy: 65.0\n",
      "=> loading checkpoint... \n",
      "done !\n",
      "Iteration: 1. Loss: 0.6228146553039551. Accuracy: 65.0\n",
      "=> loading checkpoint... \n",
      "done !\n",
      "Iteration: 1. Loss: 0.6062139272689819. Accuracy: 64.3\n",
      "=> loading checkpoint... \n",
      "done !\n",
      "Iteration: 1. Loss: 0.6217004656791687. Accuracy: 65.5\n",
      "=> loading checkpoint... \n",
      "done !\n",
      "Iteration: 1. Loss: 0.6076483130455017. Accuracy: 64.45\n",
      "=> loading checkpoint... \n",
      "done !\n",
      "Iteration: 1. Loss: 0.6200554370880127. Accuracy: 65.25\n",
      "=> loading checkpoint... \n",
      "done !\n",
      "Iteration: 1. Loss: 0.6462082862854004. Accuracy: 65.15\n",
      "=> loading checkpoint... \n",
      "done !\n",
      "Iteration: 1. Loss: 0.6337891817092896. Accuracy: 65.2\n"
     ]
    }
   ],
   "source": [
    "seq_model=dqn(2)\n",
    "#run learning and make prediction base on batch_size\n",
    "num_batches=10\n",
    "batch_size=500\n",
    "for i in range(num_batches):\n",
    "    samples=sample(*(samplemaker.memory,batch_size))\n",
    "    t,l=type_converter(samples,batch_size)\n",
    "    tr_batches=torch.from_numpy(t).float()\n",
    "    tr_labels=torch.from_numpy(l)\n",
    "    seq_model.learn(tr_batches, tr_labels,test_load,test_label,load_model=True)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one can create epoch like this \n",
    "num_epoch=10\n",
    "for epoch in range(num_epoch):\n",
    "    for i in range(num_batches):\n",
    "    samples=sample(*(samplemaker.memory,batch_size))\n",
    "    t,l=type_converter(samples,batch_size)\n",
    "    tr_batches=torch.from_numpy(t).float()\n",
    "    tr_labels=torch.from_numpy(l)\n",
    "    seq_model.learn(tr_batches, tr_labels,test_load,test_label,load_model=True) # set load_model=true to load the saved model\n",
    "    # in each epoch, remember to save the model\n",
    "    seq_model.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#seq_model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint... \n",
      "done !\n"
     ]
    }
   ],
   "source": [
    "seq_model=dqn(2)\n",
    "m=seq_model.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs:{} Variable containing:\n",
      " 0.3666  0.6334\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "0\n",
      "probs:{} Variable containing:\n",
      " 0.4514  0.5486\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#use when want to show randomly selected sample image\n",
    "\n",
    "img1=os.listdir(root+'single_prediction/')[0]\n",
    "img2=os.listdir(root+'single_prediction/')[1]\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "im1 = Image.open(root+'single_prediction/'+img1).convert('L') # use only gray \n",
    "im2=Image.open(root+'single_prediction/'+img2).convert('L')\n",
    "\n",
    "#resize the image to 80,80\n",
    "resized_1=im1.resize((80,80))\n",
    "resized_2=im2.resize((80,80))\n",
    "\n",
    "# convert to np array\n",
    "im1_np=np.asarray(resized_1).reshape(1,80,80)\n",
    "#print(im1_np)\n",
    "im2_np=np.asarray(resized_2).reshape(1,80,80)\n",
    "im1_tr=torch.from_numpy(im1_np).float()\n",
    "im2_tr=torch.from_numpy(im2_np).float()\n",
    "#print(im1_tr.size(),im2_tr.size())\n",
    "\n",
    "#make the prediction\n",
    "out1=seq_model.make_prediction(im1_tr)\n",
    "print(out1)\n",
    "out2=seq_model.make_prediction(im2_tr)\n",
    "print(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_or_dog_2.jpg is a cat, prediction is out2: dog\n",
      "cat_or_dog_1.jpg is a dog, prediction is out1 :cat\n"
     ]
    }
   ],
   "source": [
    "cat_or_dog=[\"cat\",\"dog\"]\n",
    "print(\"cat_or_dog_2.jpg is a cat, prediction is out2: {}\".format(cat_or_dog[out2]) )\n",
    "print(\"cat_or_dog_1.jpg is a dog, prediction is out1 :{}\".format(cat_or_dog[out1]) )"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
