{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month of Year      int64\n",
      "Sessions         float64\n",
      "str               object\n",
      "year              object\n",
      "month             object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month of Year</th>\n",
       "      <th>Sessions</th>\n",
       "      <th>str</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>201508</td>\n",
       "      <td>154854.0</td>\n",
       "      <td>201508</td>\n",
       "      <td>2015</td>\n",
       "      <td>08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>201509</td>\n",
       "      <td>100407.0</td>\n",
       "      <td>201509</td>\n",
       "      <td>2015</td>\n",
       "      <td>09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>201510</td>\n",
       "      <td>96439.0</td>\n",
       "      <td>201510</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>201511</td>\n",
       "      <td>79689.0</td>\n",
       "      <td>201511</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>201512</td>\n",
       "      <td>99689.0</td>\n",
       "      <td>201512</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month of Year  Sessions     str  year month\n",
       "79         201508  154854.0  201508  2015    08\n",
       "80         201509  100407.0  201509  2015    09\n",
       "81         201510   96439.0  201510  2015    10\n",
       "82         201511   79689.0  201511  2015    11\n",
       "83         201512   99689.0  201512  2015    12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil='/Users/uzi720/Desktop/'\n",
    "data=pd.read_csv(fil+\"tsIE.csv\",sep=';')\n",
    "\n",
    "data['Sessions']=data['Sessions'].astype('float')\n",
    "data['str']=data['Month of Year'].astype(str)\n",
    "data['year']=data['str'].str[:4]\n",
    "data['month']=data['str'].str[4:]\n",
    "print(data.dtypes)\n",
    "data.head()\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year       Sessions              \n",
      "                  mean           std\n",
      "0  2009   81125.666667  19857.182943\n",
      "1  2010  101085.083333  34454.598082\n",
      "2  2011  101923.750000  23524.255583\n",
      "3  2012  102986.000000  26878.443242\n",
      "4  2013  118917.083333  27364.116352\n",
      "5  2014  113627.250000  35534.987438\n",
      "6  2015  127608.166667  32894.264169\n",
      "MultiIndex(levels=[[u'Sessions', u'year'], [u'mean', u'std', u'']],\n",
      "           labels=[[1, 0, 0], [2, 0, 1]])\n",
      "<class 'pandas.core.series.Series'>\n",
      "<type 'str'> <type 'float'> <type 'float'>\n",
      "<type 'str'> 2009 <type 'numpy.float64'> 66953.0\n"
     ]
    }
   ],
   "source": [
    "result = data.groupby(['year'], as_index=False).agg(\n",
    "                      {'Sessions':['mean','std']})\n",
    "print(result)\n",
    "print(result.columns)\n",
    "year=result['year']\n",
    "print(type(year))\n",
    "yrs=year.values.tolist()\n",
    "\n",
    "mean=result['Sessions']['mean']\n",
    "std=result['Sessions']['std']\n",
    "yr_mu=mean.values.tolist()\n",
    "yr_std=std.values.tolist()\n",
    "print(type(yrs[0]),type(yr_mu[0]), type(yr_std[0]))\n",
    "print(type(data.iloc[0,3]),data.iloc[0,3],type(data.iloc[0,1]),data.iloc[0,1]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52735.0, 69856.2, 77730.8, 87020.1, 94290.20000000001, 100113.0, 108201.00000000003, 124658.0, 136022.2, 151519.7] 151519.7\n"
     ]
    }
   ],
   "source": [
    "data['Sessions'].plot()\n",
    "cuts=[data['Sessions'].quantile(.1*i) for i in range(0,10)]\n",
    "print (cuts , data['Sessions'].quantile(.90))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 [u'b', u'b', u'e', u'd', u'g', u'g', u'h', u'f', u'c', u'b', u'b', u'b', u'c', u'c', u'f', u'k', u'j', u'g', u'h', u'h', u'd', u'c', u'b', u'd', u'e', u'e', u'f', u'f', u'i', u'i', u'i', u'j', u'e', u'd', u'c', u'b', u'g', u'e', u'g', u'h', u'h', u'i', u'j', u'j', u'e', u'd', u'b', u'b', u'h', u'g', u'i', u'h', u'i', u'j', u'k', u'k', u'e', u'f', u'c', u'e', u'g', u'd', u'f', u'i', u'i', u'k', u'k', u'j', u'd', u'e', u'c', u'c', u'j', u'h', u'k', u'h', u'j', u'k', u'k', u'k', u'g', u'f', u'd', u'f']\n"
     ]
    }
   ],
   "source": [
    "# convert Session data to symbols from a,b,c,d,e,f,g,h,i,j\n",
    "symbols=[]\n",
    "for idx in data.index:\n",
    "    if data.iloc[idx,1]< cuts[0]:\n",
    "        symbols.append(normalizeString('a'))\n",
    "    elif (data.iloc[idx,1]>=cuts[0] and data.iloc[idx,1] < cuts[1]):\n",
    "        symbols.append(normalizeString('b'))\n",
    "    elif (data.iloc[idx,1]>=cuts[1] and data.iloc[idx,1] < cuts[2]):\n",
    "        symbols.append(normalizeString('c'))\n",
    "    elif (data.iloc[idx,1]>=cuts[2] and data.iloc[idx,1] < cuts[3]):\n",
    "        symbols.append(normalizeString('d'))\n",
    "    elif (data.iloc[idx,1]>=cuts[3] and data.iloc[idx,1] < cuts[4]):\n",
    "        symbols.append(normalizeString('e'))\n",
    "    elif (data.iloc[idx,1]>=cuts[4] and data.iloc[idx,1] < cuts[5]):\n",
    "        symbols.append(normalizeString('f'))\n",
    "    elif (data.iloc[idx,1]>=cuts[5] and data.iloc[idx,1] < cuts[6]):\n",
    "        symbols.append(normalizeString('g'))\n",
    "    elif (data.iloc[idx,1]>=cuts[6] and data.iloc[idx,1] < cuts[7]):\n",
    "        symbols.append(normalizeString('h'))\n",
    "    elif (data.iloc[idx,1]>=cuts[7] and data.iloc[idx,1] < cuts[8]):\n",
    "        symbols.append(normalizeString('i'))\n",
    "    elif (data.iloc[idx,1]>=cuts[8] and data.iloc[idx,1] < cuts[9]):\n",
    "        symbols.append(normalizeString('j'))\n",
    "    else :\n",
    "        symbols.append(normalizeString('k'))\n",
    "print(len(symbols),symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2009' '2010' '2011' '2012' '2013' '2014' '2015']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month of Year</th>\n",
       "      <th>Sessions</th>\n",
       "      <th>str</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>symbols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200901</td>\n",
       "      <td>66953.0</td>\n",
       "      <td>200901</td>\n",
       "      <td>2009</td>\n",
       "      <td>01</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200902</td>\n",
       "      <td>61591.0</td>\n",
       "      <td>200902</td>\n",
       "      <td>2009</td>\n",
       "      <td>02</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200903</td>\n",
       "      <td>87241.0</td>\n",
       "      <td>200903</td>\n",
       "      <td>2009</td>\n",
       "      <td>03</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200904</td>\n",
       "      <td>85263.0</td>\n",
       "      <td>200904</td>\n",
       "      <td>2009</td>\n",
       "      <td>04</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200905</td>\n",
       "      <td>100813.0</td>\n",
       "      <td>200905</td>\n",
       "      <td>2009</td>\n",
       "      <td>05</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Month of Year  Sessions     str  year month symbols\n",
       "0         200901   66953.0  200901  2009    01       b\n",
       "1         200902   61591.0  200902  2009    02       b\n",
       "2         200903   87241.0  200903  2009    03       e\n",
       "3         200904   85263.0  200904  2009    04       d\n",
       "4         200905  100813.0  200905  2009    05       g"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['symbols']=symbols\n",
    "print ( data.year.unique())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11431f810>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEcCAYAAAD6GqKbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114333350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "data.boxplot(by='year',column=\"Sessions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(87042.0, u'e'),\n",
       " (100100.0, u'f'),\n",
       " (84997.0, u'd'),\n",
       " (68835.0, u'b'),\n",
       " (66953.0, u'b'),\n",
       " (160778.0, u'k'),\n",
       " (63127.0, u'b'),\n",
       " (98061.0, u'f'),\n",
       " (85263.0, u'd'),\n",
       " (94170.0, u'e'),\n",
       " (76179.0, u'c'),\n",
       " (120469.0, u'h'),\n",
       " (151190.0, u'j'),\n",
       " (61591.0, u'b'),\n",
       " (184984.0, u'k'),\n",
       " (98969.0, u'f'),\n",
       " (67868.0, u'b'),\n",
       " (105117.0, u'g'),\n",
       " (100126.0, u'g'),\n",
       " (151173.0, u'j'),\n",
       " (145056.0, u'j'),\n",
       " (183856.0, u'k'),\n",
       " (88866.0, u'e'),\n",
       " (151661.0, u'k'),\n",
       " (79689.0, u'd'),\n",
       " (115623.0, u'h'),\n",
       " (137000.0, u'j'),\n",
       " (127260.0, u'i'),\n",
       " (124586.0, u'h'),\n",
       " (93639.0, u'e'),\n",
       " (100268.0, u'g'),\n",
       " (75694.0, u'c'),\n",
       " (77872.0, u'd'),\n",
       " (86823.0, u'd'),\n",
       " (94771.0, u'f'),\n",
       " (130357.0, u'i'),\n",
       " (100534.0, u'g'),\n",
       " (87305.0, u'e'),\n",
       " (136159.0, u'j'),\n",
       " (96439.0, u'f'),\n",
       " (140222.0, u'j'),\n",
       " (113141.0, u'h'),\n",
       " (71488.0, u'c'),\n",
       " (70083.0, u'c'),\n",
       " (134340.0, u'i'),\n",
       " (132918.0, u'i'),\n",
       " (101959.0, u'g'),\n",
       " (111176.0, u'h'),\n",
       " (87241.0, u'e'),\n",
       " (92874.0, u'e'),\n",
       " (100407.0, u'g'),\n",
       " (100813.0, u'g'),\n",
       " (152014.0, u'k'),\n",
       " (63757.0, u'b'),\n",
       " (108972.0, u'h'),\n",
       " (115923.0, u'h'),\n",
       " (78804.0, u'd'),\n",
       " (92757.0, u'e'),\n",
       " (134574.0, u'i'),\n",
       " (120154.0, u'h'),\n",
       " (77519.0, u'c'),\n",
       " (95226.0, u'f'),\n",
       " (76383.0, u'c'),\n",
       " (178785.0, u'k'),\n",
       " (135931.0, u'i'),\n",
       " (167905.0, u'k'),\n",
       " (154854.0, u'k'),\n",
       " (86293.0, u'd'),\n",
       " (136298.0, u'j'),\n",
       " (92395.0, u'e'),\n",
       " (110317.0, u'h'),\n",
       " (152050.0, u'k'),\n",
       " (104435.0, u'g'),\n",
       " (71284.0, u'c'),\n",
       " (127230.0, u'i'),\n",
       " (99689.0, u'f'),\n",
       " (99332.0, u'f'),\n",
       " (81748.0, u'd'),\n",
       " (125306.0, u'i'),\n",
       " (69759.0, u'b'),\n",
       " (67068.0, u'b'),\n",
       " (73469.0, u'c'),\n",
       " (147198.0, u'j'),\n",
       " (52735.0, u'b')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_symbols=dict(zip(data['Sessions'],data['symbols']))\n",
    "lookup_symbols.items()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['b', 'b', 'e', 'd', 'g', 'g', 'h', 'f', 'c', 'b', 'b', 'b'], ['c', 'c', 'f', 'k', 'j', 'g', 'h', 'h', 'd', 'c', 'b', 'd']), (['c', 'c', 'f', 'k', 'j', 'g', 'h', 'h', 'd', 'c', 'b', 'd'], ['e', 'e', 'f', 'f', 'i', 'i', 'i', 'j', 'e', 'd', 'c', 'b']), (['e', 'e', 'f', 'f', 'i', 'i', 'i', 'j', 'e', 'd', 'c', 'b'], ['g', 'e', 'g', 'h', 'h', 'i', 'j', 'j', 'e', 'd', 'b', 'b']), (['g', 'e', 'g', 'h', 'h', 'i', 'j', 'j', 'e', 'd', 'b', 'b'], ['h', 'g', 'i', 'h', 'i', 'j', 'k', 'k', 'e', 'f', 'c', 'e']), (['h', 'g', 'i', 'h', 'i', 'j', 'k', 'k', 'e', 'f', 'c', 'e'], ['g', 'd', 'f', 'i', 'i', 'k', 'k', 'j', 'd', 'e', 'c', 'c'])] 5\n"
     ]
    }
   ],
   "source": [
    "train_data=[]\n",
    "\n",
    "\n",
    "\n",
    "yrs=data['year'].unique().tolist()\n",
    "for yr in range(2009, 2014):\n",
    "    \n",
    "    temp=([lookup_symbols[x].encode(\"utf-8\") for x in data.loc[(data.year==str(yr))]['Sessions'].values.tolist()],[lookup_symbols[x].encode(\"utf-8\") for x in data.loc[(data.year==str(yr+1))]['Sessions'].values.tolist()])\n",
    "    train_data.append(temp)\n",
    "\n",
    "print(train_data,len(train_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(train_data), len(data['year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c': 6, 'b': 0, 'e': 1, 'd': 2, 'g': 3, 'f': 5, 'i': 9, 'h': 4, 'k': 7, 'j': 8}\n",
      "len(word_to_ix) 10\n"
     ]
    }
   ],
   "source": [
    "### use the same technique to convert your words into dictionaries \n",
    "\"\"\"\n",
    "training_data = [\n",
    "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])]\n",
    "print(\"training_data\",training_data)\n",
    "\"\"\"\n",
    "\n",
    "word_to_ix = {}\n",
    "for seq1, seq2 in train_data:\n",
    "    #print(\"sent:{}, tags:{}\".format(sent,tags))\n",
    "    for word in seq1:\n",
    "        if str(word) not in word_to_ix:\n",
    "            word_to_ix[str(word)] = len(word_to_ix)\n",
    "    for word in seq2:\n",
    "        if str(word) not in word_to_ix:\n",
    "            word_to_ix[str(word)] = len(word_to_ix)\n",
    "        \n",
    "print(word_to_ix)\n",
    "\n",
    "\n",
    "# These will usually be more like 32 or 64 dimensional.\n",
    "# We will keep them small, so we can see how the weights change as we train.\n",
    "EMBEDDING_DIM = len(word_to_ix)+ 10\n",
    "HIDDEN_DIM = 28\n",
    "print(\"len(word_to_ix)\", len(word_to_ix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 0, 1, 2, 3, 5, 4] [6, 0, 2, 3, 5, 4, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "tryin=[word_to_ix[x] for x in list(set(train_data[0][0]))] \n",
    "\n",
    "tryout=[word_to_ix[x] for x in list(set(train_data[0][1]))] \n",
    "print(tryin, tryout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, features, cls_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.rnn1 = nn.GRU(input_size=features,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=1)\n",
    "        self.dense1 = nn.Linear(hidden_size, cls_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x, hidden = self.rnn1(x, hidden)\n",
    "        x = x.select(0, maxlen-1).contiguous()\n",
    "        x = x.view(-1, hidden_size)\n",
    "        x = F.softmax(self.dense1(x))\n",
    "        return x, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size=1):\n",
    "        weight = next(self.parameters()).data\n",
    "        return Variable(weight.new(1, batch_size, hidden_size).zero_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size, n_layers):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        ## vocab_size= 2 words in vocab\n",
    "        ## embedding_dim= how many dimension you want to embed into\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        print(\"self.word_embeddings\",self.word_embeddings )\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.rnn=nn.GRU(embedding_dim, tagset_size, n_layers)\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.rnn2output = nn.Linear(hidden_dim, tagset_size)\n",
    "        print(\"self.hidden2tag\",self.hidden2tag)\n",
    "        self.hidden = self.hidden=Variable(torch.randn(n_layers,1, tagset_size))\n",
    "        \n",
    "    def forward(self, in_var):\n",
    "        embeds = self.embeddings(in_var)\n",
    "        print(\"forward embeds\",embeds) #12x16\n",
    "        lstm_out, self.hidden = self.lstm(\n",
    "            embeds.view(len(sentence), 1, -1), self.hidden)\n",
    "        print(\"forward lstm_out:{} self.hidden:{}\".format(lstm_out,self.hidden)) #12x1x56\n",
    "        tag_space = self.rnn2output(lstm_out.view(len(sentence), -1))\n",
    "        print(\"forward tag_space\", tag_space.size()) #torch.Size([12, 2])\n",
    "        tag_scores = F.log_softmax(tag_space)\n",
    "        print(\"forward tag_scores\",tag_scores) #12x2\n",
    "        return tag_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    print(\"to_ix\", to_ix)\n",
    "    print(\"idxs\", idxs)\n",
    "    tensor = torch.LongTensor(idxs)\n",
    "    print(\"tensor\", tensor)\n",
    "    print(\"prepare_sequence out tensor\",autograd.Variable(tensor))\n",
    "    return autograd.Variable(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(word_to_ix))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(rnn.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "embeds = nn.Embedding(len(word_to_ix), 10)  # 2 words in vocab, 5 dimensional embeddings\n",
    "lookup_tensor = torch.LongTensor(tryout)\n",
    "print(lookup_tensor.size(), lookup_tensor)\n",
    "hello_embed = embeds(Variable(lookup_tensor)).unsqueeze(0)\n",
    "\n",
    "print(hello_embed.view(-1,1,10))\n",
    "\"\"\"\n",
    "torch.LongTensor(5, 8, 8).random_(0, 4).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        print(\"forward output\", outpur)\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            print(\"relu output\", output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-73f99d96244d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mrnn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRNN_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_to_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mget_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtryin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mget_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-73f99d96244d>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, embedded_dim, output_dim, total_vocab_len, layers)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn2output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'dim'"
     ]
    }
   ],
   "source": [
    "tryin, tryout\n",
    "embedded_dim=21\n",
    "output_dim=len(tryout)\n",
    "layers=2\n",
    "class RNN_Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedded_dim, output_dim,total_vocab_len, layers):\n",
    "        super(RNN_Model, self).__init__()\n",
    "        self.embeds = nn.Embedding(total_vocab_len, embedded_dim)\n",
    "        self.rnn=nn.GRU(embedded_dim, output_dim, layers)\n",
    "        self.hidden=Variable(torch.randn(layers,1, output_dim))\n",
    "        self.rnn2output = nn.Linear(output_dim, output_dim)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, in_var):\n",
    "        lookup_tensor = torch.LongTensor(in_var)\n",
    "        embed = self.embeds(Variable(lookup_tensor)).unsqueeze(0)\n",
    "        output, hn = self.rnn(embed, self.hidden)\n",
    "        print(\"output.size:{}, hn:{}\".format(output.size(),hn.size()))\n",
    "        out = self.rnn2output(output[0])\n",
    "        \n",
    "        print(\"out size\",out.size())\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "rnn=RNN_Model(embedded_dim,output_dim,len(word_to_ix),2)\n",
    "get_output=rnn.forward(tryin)\n",
    "get_output=get_output.squeeze(0)\n",
    "print(get_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "multi-target not supported at /Users/soumith/code/builder/wheel/pytorch-src/torch/lib/THNN/generic/ClassNLLCriterion.c:22",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-b186855842b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtryin\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcriteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/uzi720/anaconda3/envs/py27/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/uzi720/anaconda3/envs/py27/lib/python2.7/site-packages/torch/nn/modules/loss.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         return F.nll_loss(input, target, self.weight, self.size_average,\n\u001b[0;32m--> 132\u001b[0;31m                           self.ignore_index)\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/uzi720/anaconda3/envs/py27/lib/python2.7/site-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index)\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/uzi720/anaconda3/envs/py27/lib/python2.7/site-packages/torch/nn/_functions/thnn/auto.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input, target, *args)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         getattr(ctx._backend, update_output.name)(ctx._backend.library_state, input, target,\n\u001b[0;32m---> 47\u001b[0;31m                                                   output, *ctx.additional_args)\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: multi-target not supported at /Users/soumith/code/builder/wheel/pytorch-src/torch/lib/THNN/generic/ClassNLLCriterion.c:22"
     ]
    }
   ],
   "source": [
    "t=Variable(torch.LongTensor([tryin]))\n",
    "criteria=nn.NLLLoss()\n",
    "criteria(get_output,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "rnn = nn.GRU(10, 20, 1)\n",
    "#print(torch.randn(1, 1, 10).size())\n",
    "input = Variable(torch.randn(1, 1, 10))\n",
    "#print(input)\n",
    "h0 = Variable(torch.randn(1,1, 20))\n",
    "output, hn = rnn(hello_embed, h0)\n",
    "print(output.size())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(5):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for seq1, seq2 in train_data:\n",
    "        #print(\"sentence:{} tags:{}\".format( sentence, tags))\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Also, we need to clear out the hidden state of the LSTM,\n",
    "        # detaching it from its history on the last instance.\n",
    "        model.hidden = model.init_hidden()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Variables of word indices.\n",
    "        tags=[str(t) for t in tags]\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence(tags, tag_to_ix)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model(sentence_in)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        if epoch%100 ==0 :\n",
    "            print(\"loss\",loss)\n",
    "\n",
    "# See what the scores are after training\n",
    "inputs = prepare_sequence(train_data[0][0], word_to_ix)\n",
    "tag_scores = model(inputs)\n",
    "# The sentence is \"the dog ate the apple\".  i,j corresponds to score for tag j\n",
    "#  for word i. The predicted tag is the maximum scoring tag.\n",
    "# Here, we can see the predicted sequence below is 0 1 2 0 1\n",
    "# since 0 is index of the maximum value of row 1,\n",
    "# 1 is the index of maximum value of row 2, etc.\n",
    "# Which is DET NOUN VERB DET NOUN, the correct sequence!\n",
    "print(tag_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
